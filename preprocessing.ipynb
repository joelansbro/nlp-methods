{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Preprocessing\n",
    "\n",
    "Case Folding - lower or upper casing all tokens - can catch duplicate tokens where single difference is upper case - can result in information loss EG: the name 'Cook' may be lost and combined with the verb 'cook'\n",
    "\n",
    "Stop word removal - words that occur frequently but carry little information\n",
    "eg: the, a, of, this, that etc\n",
    "removal again depends on the task at hand eg: Sentiment analysis would negatively effect sentiment where emphasis on articles influences sentiment\n",
    "eg: I need a house - I need the house -> article necessary for full understanding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"He told Dr.Lovato that he was done with the tests and would post the results shortly.\"\n",
    "doc = nlp(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'told', 'dr.', 'lovato', 'that', 'he', 'was', 'done', 'with', 'the', 'tests', 'and', 'would', 'post', 'the', 'results', 'shortly', '.']\n"
     ]
    }
   ],
   "source": [
    "print([t.lower_ for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[He, 'told', 'dr.', 'lovato', 'that', 'he', 'was', 'done', 'with', 'the', 'tests', 'and', 'would', 'post', 'the', 'results', 'shortly', '.']\n"
     ]
    }
   ],
   "source": [
    "# apply conditional to ignore case-folding at beginning of sentence\n",
    "print([t.lower_ if not t.is_sent_start else t for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'at', 'ten', 'part', 'you', 'nothing', 'her', 'well', 'it', 'none', 'own', 'down', 'due', 'other', 'him', 'quite', 'ever', 'over', 'whatever', 'until', 'whom', 'three', 'give', 'already', 'without', 'above', 'however', 'nevertheless', 'mostly', 'thence', 'namely', 'against', \"'ve\", 'n‘t', 'make', 'who', 'whole', 'somewhere', 'us', 'my', 'keep', 'only', 'both', 'off', '‘s', 'across', 'from', 'up', 'latter', 'hence', 'somehow', 'five', 'seeming', 'them', 'fifteen', '‘m', 'same', 'anything', 'forty', 'thereupon', 'hereafter', 'even', 'whose', 'full', 'top', 'along', 'any', 'herein', 'she', 'whereupon', 'show', 'thru', 'next', 'ca', 'could', '‘ll', 'becoming', 'seem', 'anyone', 'these', 'besides', '‘d', 'please', 'still', 'six', 'serious', 'have', 'beside', 'there', 'beforehand', 'themselves', 'those', 'seems', 'rather', 'more', 'else', 'very', 'fifty', 'per', 'two', 'hereby', 'sixty', 'do', 'amongst', 'eleven', 'others', \"'s\", 'whence', 'cannot', 'every', 'four', 'several', '’s', 'everything', 'almost', 'that', 'again', 'using', 'put', 'wherever', 'whoever', 'some', 'becomes', 'perhaps', 'did', 'formerly', 'our', 'except', 'may', 'name', 'yours', 'sometime', 'in', 'i', 'has', 'be', 'enough', 'is', 'thereby', \"'d\", 'and', 'all', 'amount', 'between', 'but', 'nor', 'each', 'toward', 'front', 'twenty', 'hereupon', 'eight', 'nobody', 'onto', 'elsewhere', 'much', 'can', 'n’t', 'would', 'were', 'for', 'neither', 'what', '‘re', 'otherwise', 'will', 'through', 'its', 'third', 'about', 'out', 'now', 'under', 'never', 'we', 'few', 'such', 'sometimes', 'than', 'when', 'always', 'no', 'most', 'towards', 'meanwhile', 'yet', 'anyway', '’m', 'his', 'whereby', 'twelve', 'nowhere', 'least', 'upon', 'various', '’re', 'latterly', 'thereafter', 'yourself', 'this', 'yourselves', 'whether', 'am', '’d', 'while', 're', 'someone', 'first', 'bottom', 'move', '‘ve', 'where', \"'re\", 'how', 'must', 'take', 'either', 'below', 'really', 'something', 'or', 'many', 'after', 'since', 'ours', 'also', 'here', \"'m\", 'became', 'during', 'by', 'become', 'regarding', 'used', 'among', 'go', 'to', 'behind', 'done', 'ourselves', 'of', 'herself', 'the', 'before', 'whenever', 'being', 'therefore', 'indeed', 'their', 'a', 'though', 'does', 'moreover', 'on', 'are', 'often', 'himself', 'why', 'too', 'made', 'then', 'everyone', 'anywhere', 'around', 'beyond', 'was', 'everywhere', 'he', 'because', 'whereafter', '’ll', 'via', 'seemed', 'whither', 'throughout', 'with', 'nine', 'alone', \"n't\", 'together', 'if', 'thus', 'doing', 'hundred', 'therein', 'unless', 'back', 'anyhow', 'whereas', 'say', 'your', 'one', 'although', 'former', 'not', 'just', 'last', \"'ll\", 'empty', 'been', 'mine', 'an', 'further', 'call', 'get', 'another', '’ve', 'side', 'so', 'as', 'myself', 'within', 'wherein', 'might', 'noone', 'into', 'itself', 'had', 'me', 'see', 'once', 'which', 'hers', 'less', 'they', 'should', 'afterwards'}\n"
     ]
    }
   ],
   "source": [
    "# Default stop words within en_core_web_sm\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[told, Dr., Lovato, tests, post, results, shortly, .]\n"
     ]
    }
   ],
   "source": [
    "# isolate words that are not stop words ergo unique\n",
    "print([t for t in doc if not t.is_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    " This is the process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word's lemma, or dictionary form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('He', 'he'),\n",
       " ('told', 'tell'),\n",
       " ('Dr.', 'Dr.'),\n",
       " ('Lovato', 'Lovato'),\n",
       " ('that', 'that'),\n",
       " ('he', 'he'),\n",
       " ('was', 'be'),\n",
       " ('done', 'do'),\n",
       " ('with', 'with'),\n",
       " ('the', 'the'),\n",
       " ('tests', 'test'),\n",
       " ('and', 'and'),\n",
       " ('would', 'would'),\n",
       " ('post', 'post'),\n",
       " ('the', 'the'),\n",
       " ('results', 'result'),\n",
       " ('shortly', 'shortly'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the lematization\n",
    "[(t.text, t.lemma_) for t in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Preprocessing\n",
    "\n",
    "Part-of-Speech Tagging, Named Entity Recognition, and Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('He', 'PRON'),\n",
       " ('told', 'VERB'),\n",
       " ('Dr.', 'PROPN'),\n",
       " ('Lovato', 'PROPN'),\n",
       " ('that', 'SCONJ'),\n",
       " ('he', 'PRON'),\n",
       " ('was', 'AUX'),\n",
       " ('done', 'VERB'),\n",
       " ('with', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('tests', 'NOUN'),\n",
       " ('and', 'CCONJ'),\n",
       " ('would', 'AUX'),\n",
       " ('post', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('results', 'NOUN'),\n",
       " ('shortly', 'ADV'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part of Speech tagging can be accessed via the pos_ attribute\n",
    "[(t.text, t.pos_) for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'He' : 'pronoun'\n",
      "'told' : 'verb'\n",
      "'Dr.' : 'proper noun'\n",
      "'Lovato' : 'proper noun'\n",
      "'that' : 'subordinating conjunction'\n",
      "'he' : 'pronoun'\n",
      "'was' : 'auxiliary'\n",
      "'done' : 'verb'\n",
      "'with' : 'adposition'\n",
      "'the' : 'determiner'\n",
      "'tests' : 'noun'\n",
      "'and' : 'coordinating conjunction'\n",
      "'would' : 'auxiliary'\n",
      "'post' : 'verb'\n",
      "'the' : 'determiner'\n",
      "'results' : 'noun'\n",
      "'shortly' : 'adverb'\n",
      "'.' : 'punctuation'\n"
     ]
    }
   ],
   "source": [
    "# describe the POS tag via .explain() - eg 'PRON' = pronoun\n",
    "spacy.explain('PRON')\n",
    "\n",
    "for t in doc:\n",
    "    print(\"'{text}' : '{explain}'\".format(text=t.text, explain=spacy.explain(t.pos_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('He', 'PRP'),\n",
       " ('told', 'VBD'),\n",
       " ('Dr.', 'NNP'),\n",
       " ('Lovato', 'NNP'),\n",
       " ('that', 'IN'),\n",
       " ('he', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('done', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('tests', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('would', 'MD'),\n",
       " ('post', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('results', 'NNS'),\n",
       " ('shortly', 'RB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS tag above are course-grained tags. We can access fine-grained tags via tag_ attribute, which provide more detailed information\n",
    "[(t.text, t.tag_) for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'He' : 'pronoun, personal'\n",
      "'told' : 'verb, past tense'\n",
      "'Dr.' : 'noun, proper singular'\n",
      "'Lovato' : 'noun, proper singular'\n",
      "'that' : 'conjunction, subordinating or preposition'\n",
      "'he' : 'pronoun, personal'\n",
      "'was' : 'verb, past tense'\n",
      "'done' : 'verb, past participle'\n",
      "'with' : 'conjunction, subordinating or preposition'\n",
      "'the' : 'determiner'\n",
      "'tests' : 'noun, plural'\n",
      "'and' : 'conjunction, coordinating'\n",
      "'would' : 'verb, modal auxiliary'\n",
      "'post' : 'verb, base form'\n",
      "'the' : 'determiner'\n",
      "'results' : 'noun, plural'\n",
      "'shortly' : 'adverb'\n",
      "'.' : 'punctuation mark, sentence closer'\n"
     ]
    }
   ],
   "source": [
    "for t in doc:\n",
    "    print(\"'{text}' : '{explain}'\".format(text=t.text, explain=spacy.explain(t.tag_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition\n",
    "There are multiple ways to access Named Entities, one is via ent_type_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Volkswagen', 'ORG'),\n",
       " ('is', ''),\n",
       " ('developing', ''),\n",
       " ('an', ''),\n",
       " ('electric', ''),\n",
       " ('sedan', ''),\n",
       " ('which', ''),\n",
       " ('could', ''),\n",
       " ('potentially', ''),\n",
       " ('come', ''),\n",
       " ('to', ''),\n",
       " ('America', 'GPE'),\n",
       " ('next', 'DATE'),\n",
       " ('fall', 'DATE'),\n",
       " ('.', '')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement2 = \"Volkswagen is developing an electric sedan which could potentially come to America next fall.\"\n",
    "document = nlp(statement2)\n",
    "[(t.text, t.ent_type_) for t in document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Volkswagen' : 'Companies, agencies, institutions, etc.'\n",
      "'America' : 'Countries, cities, states'\n",
      "'next' : 'Absolute or relative dates or periods'\n",
      "'fall' : 'Absolute or relative dates or periods'\n"
     ]
    }
   ],
   "source": [
    "for t in document:\n",
    "    if t.ent_type_:\n",
    "        print(\"'{text}' : '{explain}'\".format(text=t.text, explain=spacy.explain(t.ent_type_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Volkswagen' : 'Companies, agencies, institutions, etc.'\n",
      "'America' : 'Countries, cities, states'\n",
      "'next fall' : 'Absolute or relative dates or periods'\n"
     ]
    }
   ],
   "source": [
    "# another method to check a Named Entity is via accessing the entities themselves from the document\n",
    "for ent in document.ents:\n",
    "    if ent.label_:\n",
    "        print(\"'{text}' : '{explain}'\".format(text=ent.text, explain=spacy.explain(ent.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Volkswagen', 'ORG', 0, 10), ('America', 'GPE', 75, 82), ('next fall', 'DATE', 83, 92)]\n"
     ]
    }
   ],
   "source": [
    "# can also access the position of entities\n",
    "print([(ent.text, ent.label_, ent.start_char, ent.end_char) for ent in document.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisers \n",
    "We can use visualizers for both parsing and named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Volkswagen\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is developing an electric sedan which could potentially come to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    America\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    next fall\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(document, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c01703fe9a6a4004a4179b749a5cd048-0\" class=\"displacy\" width=\"1450\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">She</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">enrolled</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">course</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">university</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c01703fe9a6a4004a4179b749a5cd048-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c01703fe9a6a4004a4179b749a5cd048-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c01703fe9a6a4004a4179b749a5cd048-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c01703fe9a6a4004a4179b749a5cd048-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M390.0,266.5 L398.0,254.5 382.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c01703fe9a6a4004a4179b749a5cd048-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c01703fe9a6a4004a4179b749a5cd048-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c01703fe9a6a4004a4179b749a5cd048-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c01703fe9a6a4004a4179b749a5cd048-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,266.5 L753.0,254.5 737.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c01703fe9a6a4004a4179b749a5cd048-0-4\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c01703fe9a6a4004a4179b749a5cd048-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,266.5 L933.0,254.5 917.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c01703fe9a6a4004a4179b749a5cd048-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c01703fe9a6a4004a4179b749a5cd048-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c01703fe9a6a4004a4179b749a5cd048-0-6\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c01703fe9a6a4004a4179b749a5cd048-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unidoc = nlp(\"She enrolled in the course at the university\")\n",
    "\n",
    "displacy.render(unidoc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'She' : 'nominal subject'\n",
      "'enrolled' : 'None'\n",
      "'in' : 'prepositional modifier'\n",
      "'the' : 'determiner'\n",
      "'course' : 'object of preposition'\n",
      "'at' : 'prepositional modifier'\n",
      "'the' : 'determiner'\n",
      "'university' : 'object of preposition'\n"
     ]
    }
   ],
   "source": [
    "# dependency information can be accessed via the .dep_ attribute\n",
    "for t in unidoc:\n",
    "    if t.dep_:\n",
    "        print(\"'{text}' : '{explain}'\".format(text=t.text, explain=spacy.explain(t.dep_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "842fbf2151771c5fab737f7e91cae4a6b3fd587e0ef9c8eecff0f9eb53e93c36"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

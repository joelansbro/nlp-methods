Running Sentiment analysis over a larger amount of articles today to see what we can describe


Also I forgot that running in a dataframe and describing it will return a whole range of cool things:
count	53.000000	53.0	53.0
mean	1009.377358	1.0	1.0
std	1605.028543	0.0	0.0
min	1.000000	1.0	1.0
25%	6.000000	1.0	1.0
50%	204.000000	1.0	1.0
75%	1113.000000	1.0	1.0
max	6525.000000	1.0	1.0


Sentiment analysis is currently taking place via spacytextblob - https://github.com/SamEdwardes/spacytextblob

Install:
Install spacytextblob from PyPi.

pip install spacytextblob

TextBlob requires additional data to be downloaded before getting started.

python -m textblob.download_corpora

spaCy also requires that you download a model to get started.

python -m spacy download en_core_web_sm


spacytextblob uses TextBlob's sentiment analysis - https://textblob.readthedocs.io/en/dev/api_reference.html#textblob.blob.TextBlob.sentiment

sentiment

    Return a tuple of form (polarity, subjectivity ) where polarity is a float within the range [-1.0, 1.0] and subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective.
    Return type:	namedtuple of the form Sentiment(polarity, subjectivity)

sentiment_assessments

    Return a tuple of form (polarity, subjectivity, assessments ) where polarity is a float within the range [-1.0, 1.0], subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective, and assessments is a list of polarity and subjectivity scores for the assessed tokens.
    Return type:	namedtuple of the form ``Sentiment(polarity, subjectivity,

    assessments)``

 polarity

    Return the polarity score as a float within the range [-1.0, 1.0]
    Return type:	float


TextBlob is a Python library for Natural Language Processing (NLP). Sentiment analysis is one of many NLP tasks that TextBlob supports.

The sentiment property in TextBlob returns a polarity score and a subjectivity score for the input text.

    The polarity score ranges from -1 to 1, where -1 means extremely negative, and 1 means highly positive. A score near 0 means neutral sentiment.
    The subjectivity score ranges from 0 to 1, where 0 means extremely objective and 1 means highly subjective.

Sentiment(polarity=0.8, subjectivity=0.75) = sentence has a subjective and positive sentiment


When computing a sentiment for a single word, TextBlob employs the “averaging” technique, which is applied to polarity values to calculate a polarity score for a single word, and thus a similar procedure applies to every single word, resulting in a combined polarity for larger texts.


comparisons
https://neptune.ai/blog/sentiment-analysis-python-textblob-vs-vader-vs-flair

Textblob will ignore the words that it doesn’t know, it will consider words and phrases that it can assign polarity to and averages to get the final score.

The article compares VADER and Flair with TextBlob on Twitter commentary
and it finds:
Algorithm   Accuracy
TextBlob    56%
VADER       56%
Flair       50%
USE Model   0.775

Their results showed that neither one was particularly accurate about Twitter sentiment, 
This paper:
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8844448/
Shows that in results, textBlob performed at 78% accuracy


Big_Data Article Set Analysis

Articles used in this search:
['Adaptive data analysis', 'Analyzing Housing Prices in Berkeley', 'Approaching fairness in machine learning', 'Gradient descent learns linear dynamical systems', 'Graph Data Visualization With GraphQL & react-force-graph', 'Illustrated Guide to ROC and AUC', 'LOCF and Linear Imputation with PostgreSQL', 'Master Python`s pandas library with these 100 tricks', 'Mimicking Writing Style With Markov Chains', 'No Cost Data Scraping With GitHub Actions And Neo4j Aura', 'Optimization of Scientific Code with Cython: Ising Model', 'Recommending Subreddits by Computing User Similarity: An Introduction to Machine Learning in Python', 'Reduce GPU costs with startup scripts on the Google Cloud Engine', 'Simulating Chutes & Ladders in Python', 'Slow Data', 'TODOs for Effective ML teamwork at an early-stage startup', 'The Softmax Function Derivative (Part\xa03)', 'The Waiting Time Paradox, or, Why Is My Bus Always Late?', 'Thoughts on Trace Estimation in Deep Learning - Sebastian Nowozins slow blog', 'YourTTS - Swiss knife for Text-to-Speech', 'writing', 'writing | trey causey']
Exist within the maindb.sqlite file

For my own notes, I wondered whether the word count would impact the polarity
if there was some correlation that smoothed things out
I hypothesised that the more words, the more chance the article would be smoothed out, even if it was
very clear the article was positive
saved down the results
Polarity seems higher for articles where the word count is lower, however the articles used a fairly positive sounding, so this does sound accurate
the range is between the highest and lowest sentiment score is as follows: 0.04717963040543682

Big_Data polarity range: 0.04717963040543682

Ensemble Learning may be useful to employ here:
https://en.wikipedia.org/wiki/Ensemble_learning - which means combine more of the sentiment analyses for better results

TODO: Employ both VADER and FLAIR in the NLP extraction and see what we get, and if we should aggregate the results.
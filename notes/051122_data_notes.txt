Running Sentiment analysis over a larger amount of articles today to see what we can describe


Also I forgot that running in a dataframe and describing it will return a whole range of cool things:
count	53.000000	53.0	53.0
mean	1009.377358	1.0	1.0
std	1605.028543	0.0	0.0
min	1.000000	1.0	1.0
25%	6.000000	1.0	1.0
50%	204.000000	1.0	1.0
75%	1113.000000	1.0	1.0
max	6525.000000	1.0	1.0


Sentiment analysis is currently taking place via spacytextblob - https://github.com/SamEdwardes/spacytextblob

Install:
Install spacytextblob from PyPi.

pip install spacytextblob

TextBlob requires additional data to be downloaded before getting started.

python -m textblob.download_corpora

spaCy also requires that you download a model to get started.

python -m spacy download en_core_web_sm


spacytextblob uses TextBlob's sentiment analysis - https://textblob.readthedocs.io/en/dev/api_reference.html#textblob.blob.TextBlob.sentiment
lead dev behind TextBlob - https://github.com/sloria
struggling to find any meaningful written whitepaper or journal article around Textblob however I believe the comparisons between Textblob and other NLP methods should be useful to justify it's reliability

sentiment

    Return a tuple of form (polarity, subjectivity ) where polarity is a float within the range [-1.0, 1.0] and subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective.
    Return type:	namedtuple of the form Sentiment(polarity, subjectivity)

sentiment_assessments

    Return a tuple of form (polarity, subjectivity, assessments ) where polarity is a float within the range [-1.0, 1.0], subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective, and assessments is a list of polarity and subjectivity scores for the assessed tokens.
    Return type:	namedtuple of the form ``Sentiment(polarity, subjectivity,

    assessments)``

 polarity

    Return the polarity score as a float within the range [-1.0, 1.0]
    Return type:	float


TextBlob is a Python library for Natural Language Processing (NLP). Sentiment analysis is one of many NLP tasks that TextBlob supports.

The sentiment property in TextBlob returns a polarity score and a subjectivity score for the input text.

    The polarity score ranges from -1 to 1, where -1 means extremely negative, and 1 means highly positive. A score near 0 means neutral sentiment.
    The subjectivity score ranges from 0 to 1, where 0 means extremely objective and 1 means highly subjective.

Sentiment(polarity=0.8, subjectivity=0.75) = sentence has a subjective and positive sentiment


When computing a sentiment for a single word, TextBlob employs the “averaging” technique, which is applied to polarity values to calculate a polarity score for a single word, and thus a similar procedure applies to every single word, resulting in a combined polarity for larger texts.


comparisons
https://neptune.ai/blog/sentiment-analysis-python-textblob-vs-vader-vs-flair

Textblob will ignore the words that it doesn’t know, it will consider words and phrases that it can assign polarity to and averages to get the final score.

The article compares VADER and Flair with TextBlob on Twitter commentary
and it finds:
Algorithm   Accuracy
TextBlob    56%
VADER       56%
Flair       50%
USE Model   0.775

Their results showed that neither one was particularly accurate about Twitter sentiment, 
This paper:
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8844448/
Shows that in results, textBlob performed at 78% accuracy


Big_Data Article Set Analysis

Articles used in this search:
['Adaptive data analysis', 'Analyzing Housing Prices in Berkeley', 'Approaching fairness in machine learning', 'Gradient descent learns linear dynamical systems', 'Graph Data Visualization With GraphQL & react-force-graph', 'Illustrated Guide to ROC and AUC', 'LOCF and Linear Imputation with PostgreSQL', 'Master Python`s pandas library with these 100 tricks', 'Mimicking Writing Style With Markov Chains', 'No Cost Data Scraping With GitHub Actions And Neo4j Aura', 'Optimization of Scientific Code with Cython: Ising Model', 'Recommending Subreddits by Computing User Similarity: An Introduction to Machine Learning in Python', 'Reduce GPU costs with startup scripts on the Google Cloud Engine', 'Simulating Chutes & Ladders in Python', 'Slow Data', 'TODOs for Effective ML teamwork at an early-stage startup', 'The Softmax Function Derivative (Part\xa03)', 'The Waiting Time Paradox, or, Why Is My Bus Always Late?', 'Thoughts on Trace Estimation in Deep Learning - Sebastian Nowozins slow blog', 'YourTTS - Swiss knife for Text-to-Speech', 'writing', 'writing | trey causey']
Exist within the maindb.sqlite file

For my own notes, I wondered whether the word count would impact the polarity
if there was some correlation that smoothed things out
I hypothesised that the more words, the more chance the article would be smoothed out, even if it was
very clear the article was positive
saved down the results
Polarity seems higher for articles where the word count is lower, however the articles used a fairly positive sounding, so this does sound accurate
the range is between the highest and lowest sentiment score is as follows: 0.04717963040543682

Big_Data polarity range: 0.04717963040543682 <- the maths is wrong discount this

Ensemble Learning may be useful to employ here:
https://en.wikipedia.org/wiki/Ensemble_learning - which means combine more of the sentiment analyses for better results

TODO: Employ both VADER and FLAIR in the NLP extraction and see what we get, and if we should aggregate the results.


71122 replaced the 22 articles with 210 articles for a wider sample

210 articles took about a minute to process, 55 seconds in all, when we run this job on pyspark, 
run the nlp function inside a pyspark lambda job this will divide up the table in parts on each executor and speed it up considerably

amongst 210 articles the polarity range is 0.519 which is a larger improvement on the smaller amount of articles 0.412* + -0.106

The polarity and word count scatter plot is a lot more of what I wanted to see - it has a range of sentiment polarity for each article spread out evenly. Though my hypothesis looks correct - as the word count increases, the more tokens in the text begin to weight each other out and the sentiment begins to smooth out towards zero, meaning that the more words in an article the less polarised negative or positive it becomes. 
This isn't necessarily a draw back - one would assume the more content of a post the greater the likelihood of an even assessment of the topic area. That said the graph does even out overall at 0.1 which does suggest more positive polarity bias, which may just be a feature of blog articles about a technology overall - the blogs chosen in the 210 corpus are taken from Google results which would emphasise more positive rounded articles than negative or inflamatory articles, and when writing about a technology topic aimed at teaching people a tech, an author expectedly would be promoting the technology, not denegrating it. 

Looking at outliers:
The lowest polarity contains a lot of the word "Previously" which doesn't strike me as overall negative. 
the highest polarity isn't particularly interesting to look at as it's so short - 31 words. Still, it is positive, it's about the fact that there are lots of jobs available for Data Scientists, which is positive. 
Coffee and Tea in charts is rated as largely positive at 0.4, however it's one of the excerpts taken as content so it's data is low in worth.
Informatica Data Quality Review is rated fairly high at 0.258, and the article is a positive review (I believe an advertisment) for a technology

Moving on to negative polarity
The softmax function derivative is rated -0.069 so close to neutral sentiment - reading it it's how to improve on a not very good algorithm, so this would make sense for neutrality

Looking at AI,ML, NN and DL:a visual explanation,
is rated dead neutral which is strange, the visual side of the article hasn't been parsed so we could consider the data incomplete, also the words Artificial and Popular are both rated -0.6 and 0.6 so they cancel one another out, low word count at 46 these are the only ones with a polarity score. Funny that artificial here has been used in the negative sense (this coffee tastes artificial) whereas the context is missing that the article is about artificial intelligence 

Finding the closest parent of a git branch is also rated neutral, this is fine however because the problem lies with the article, it's an article that just presents a code snippet, no opinion mentioned, this should be excluded from results. 

the most egregious outlier here is the Nethack Reinforcement Learning article - it skews just negative, at -0.0493 polarity, but it's fine it's an advert for a game, the issue comes with several negative polarity words which in context just describe the game - ie: [enemy]...can really _damage_the agent. That said, it only skews barely under the metric of positive, perhaps more sentiment analysis libraries would be able to boost this significantly. 


----
Articles used in this search: ['10 Most Influential People in Data Analytics', '3 Use Cases for Real-Time Blockchain Analytics', 'A Year After: Has Blockchain Changed Advertising by 2022?', 'AI, ML, NN and DL: a visual explanation', 'Abusing AI', 'Accessible visualization with Olli JavaScript library', 'Adaptive data analysis', 'Alpine Investors Makes Bet on Harnessing Big Data', 'An 8-hour course on R and Data\xa0Mining', 'Analyzing Housing Prices in Berkeley', 'Announcing GA of DataFlow Functions - Cloudera Blog', 'Announcing General Availability of Delta Sharing - The Databricks Blog', 'Approaching fairness in machine learning', 'Arcadia aggregates energy data for companies to build climate-friendly products, raises $200M', 'Artificial intelligence in insurance: Use cases and 4 best impacts', 'Automate data archival for Amazon Redshift time series tables | Amazon Web Services', 'Being Irresponsible About\xa0AI', 'Best practices when sharing your data analysis - Jupyter Notebooks', 'Big data challenges for CMOs and cherry-picking chiefs', 'Building Blocks for Modern Data Management: Data Subassemblies and Data Products – Part 1', 'Building an accessible agricultural data community with the National Agricultural Producers Data Cooperative', 'CFP: AusDM 2018, Bathurst, Australia, 28-30 Nov\xa02018', 'Can BigQuery, Snowflake, and Redshift Handle Real-Time Data Analytics?', 'Can a dentist become a data scientist? (spoiler: YES)', 'Cloudera Recognized as 2022 Gartner® Peer Insights™ - Cloudera Blog', 'Coffee versus tea in charts', 'Cohort Analysis on Databricks Using Fivetran, dbt and Tableau', 'Comments', 'Common streaming data enrichment patterns in Amazon Kinesis Data Analytics for Apache Flink | Amazon Web Services', 'Coronavirus data analysis with R, tidyverse and\xa0ggplot2', 'Cross-border data transfer in China', 'Current Salaries for AI Professionals and Data\xa0Scientists', 'Data Into Dollars: Can You Turn Your Data Into Revenue?', 'Data governance framework: Best practices, examples, and providers (2022)', 'Data-savvy Organizations Are 9.5% More Profitable: Splunk', 'DataRobot Announces Launch of Dedicated Managed AI Cloud', 'Databricks Expands New Brickbuilder Solutions for Financial Services', 'Developing Kafka Data Pipelines Just Got Easier', 'Dis-aggregated hardware', 'Dive into Deep Learning', 'Easy R Tutorials with Dev Containers', 'Essential Productivity Hacks in Cloud-Centric Workplaces', 'Feature Deep Dive: Watermarking in Apache Spark Structured Streaming', 'Fighting Data Silos with Data Literacy and Transparency for All', 'Finding the closest parent of a git branch.', 'Gradient descent learns linear dynamical systems', 'Graph Data Visualization With GraphQL & react-force-graph', 'How AI Helps the Educational Sector', 'How To Select The Correct Visualization Technique for Your Data', 'How to Build Real-Time Personalization in 2022', 'How to Build a Data Strategy That Works in Your Industry', 'How to Migrate Your Data and AI Workloads to Databricks With the AWS Migration Acceleration Program', 'How to Troubleshoot and Fix Common Technical SEO Problems?', 'I-GUIDE: Increasing Sustainability by Harnessing Data', 'Illustrated Guide to ROC and AUC', 'Impact of Big Data Analytics on People’s Health: Overview of Systematic Reviews and Recommendations for Future Studies', 'Informatica Data Quality review', 'Ingest streaming data to Apache Hudi tables using AWS Glue and Apache Hudi DeltaStreamer | Amazon Web Services', 'Interview: Ashok Reddy, Chief Executive Officer, KX', 'Intro to NLP, new course on Openclassrooms', 'It’s your Life – It’s your Data', 'LOCF and Linear Imputation with PostgreSQL', 'Low-Code Software Development: From Crisis Technology to Core Technology', 'Machine learning vs data science: Differences, similarities, and future (2022)', 'Master Python`s pandas library with these 100 tricks', 'Mimicking Writing Style With Markov Chains', 'National Workshop on Data Science Education Featured Multiple Hub Talks', 'Nethack Reinforcement Learning', 'New Flink Startup Immerok Gets Off the Ground', 'New statistical learning course on openclassroooms', 'News and Advice on the World`s Latest Innovations', 'News and Advice on the World`s Latest Innovations | ZDNET', 'No Cost Data Scraping With GitHub Actions And Neo4j Aura', 'Optimization of Scientific Code with Cython: Ising Model', 'PlanetScale announces new database analysis and performance features', 'PyData NYC: The Really Short Version', 'REINVENTING SOCIETY IN THE WAKE OF BIG DATA | Edge.org', 'Recommending Subreddits by Computing User Similarity: An Introduction to Machine Learning in Python', 'Reduce GPU costs with startup scripts on the Google Cloud Engine', 'Restricting Libraries in JVM Compute Platforms', 'Risk vs. Loss', 'Serverless NiFi Flows with DataFlow Functions: The Next Step in the DataFlow Service Evolution - Cloudera Blog', 'Seven Rights Of Data Storytelling', 'Simulating Chutes & Ladders in Python', 'Slow Data', 'Solving MNIST with a Neural Network from the ground\xa0up', 'Stripe launches Data Pipeline to help users sync payments data with Redshift and Snowflake', 'TODOs for Effective ML teamwork at an early-stage startup', 'Teaching Data Science at UM6P', 'The Age of Big Data (Published 2012)', 'The Databricks Blog', 'The Future of the Data Lakehouse - Open - Cloudera Blog', 'The Impact of Technology in Healthcare', 'The Metaverse Will Be Built on Big Data and User Trust.', 'The Research Process', 'The Similarities of Solving Data Problems and Rubik’s Cubes', 'The Softmax Function Derivative (Part\xa03)', 'The State Of The Insights-Driven Business, 2022', 'The Waiting Time Paradox, or, Why Is My Bus Always Late?', 'The Women in AI Breakfast is a go, and nominations for the Women in AI Awards now open', 'The future of data architecture is hybrid: choosing your hybrid-first data strategy starts at Cloudera Now 2022 - Cloudera Blog', 'Thoughts on Trace Estimation in Deep Learning - Sebastian Nowozins slow blog', 'To Improve Enterprise Visibility, Shine a Light on Dark Data and Shadow IT', 'Top 10 Easy Data Analysis Methods and Techniques', 'Top 10 benefits of data quality', 'Unlock operational excellence through data', 'What Are the Most Serious Privacy Concerns Regarding Big Data?', 'What Are the Three Main Goals of Data Lifecycle Management', 'What Does It Mean for a Data Catalog to Be Powered by a Knowledge Graph?', 'What Is Data Modeling? Process, Tools, and Best Practices', 'What Is Data Normalization And How To Work?', 'What data integration means for workforce efficiencies', 'What does a data modeler do?', 'What is Data Observability and Why It`s Important for Modern Business Models', 'What is data in motion: Encryption, states, security and more', 'What to expect from Strata Conference 2015? An empirical outlook.', 'Who Benefits from AI Writers?', 'Why IoT is not the solution to supply chain issues', 'Why The Future of DTC Business Plans Includes a Data Strategy', 'Wide range of data exploration tools', 'YourTTS - Swiss knife for Text-to-Speech', 'writing', 'writing | trey causey']




----------------------------------------------------------------------------
VADER

https://github.com/cjhutto/vaderSentiment

for citation of the whitepaper
Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.

Says it's a sentiment analysis tool that's been used for social media, however does state that it can be used for other purposes

Ran in VADER into the sentiment_analysis function alongside spacytextblob,
significantly increases the run time of the function over 210 articles to 1 minute, 15 seconds.


The compound score is computed by summing the valence scores of each word in the lexicon, adjusted according to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive). This is the most useful metric if you want a single unidimensional measure of sentiment for a given sentence. Calling it a 'normalized, weighted composite score' is accurate.

ranges between -1 and 1 just like the SpacyTextBlob

Ran the Vader polarity scores against word count, and something interesting happens,
Vader rates the 210 articles very highly positive, the general trend does agree with textblob, textblob also rated the articles as positive, but vader regards the articles MUCH MORE positive in comparison. When scanning over the articles, I would agree more with Vader.
The general Vader graph does have some negatively skewed articles which I now will need to investigate

the polarity range for VADER for 210 was 1.9939, (1.0 + 0.9939) essentially the spectrum of scores

A box plot shows the large difference between TB polarity scores, which fall within a narrower range, with Vader a much more generous range closer towards 1. 

Taking a fine grain look, the vader polarity has some flaws:
article: TODOs for Effective ML teamwork had vader_polarity of 0.9996 which is great, but reading the article has a lot of neutral language. 
This is something to consider with vader as the compound polarity score has added up the positive and the neutral score, so it looks like it's higher.

Ergo: the TODOs example has only 0.113 positive score from VADER with 0.836 taken neutral, and TextBlob rated it similar, 0.129 <- this score is similar to Vaders' 0.113

When we look instead of compound at positive metric, the scatter plot correlates with Textblob.
the metric 071122_210Vader_TB_Positive_KDE.png shows this abundantly that they do track in line with one another#

I think I would be happy to use both methods for Ensemble Learning

--------------------------------------------------------------------------------
FLAIR


have to generate more verbose code for this one, and when run on a single instance it took a long time,
cpu isn't happy with it as far as I can tell....

sentiment value generates a score up to 1, similar to the other NLPs,

Im splitting content into sentences, running the classifier, getting the result of a positive or negative sentiment and adding them to lists. At that point im getting the mean average of sentiment scores from an article and then subtracting the negative sentiment compound from the positive sentiment compound.

At this point my CPU takes off like a jet engine and the operation to find a single sentiment for one article takes 45 seconds, this is a bad idea.

I am going to see if there's a wrapper for this similar to SpacytextBlob

there's a faster library that is apparently slightly less accurate called sentiment-fast which used RNN, which achieves slightly slower accuracy, going to try that.

can't even load sentiment-fast as it kills my ipynb kernel

at this point I could keep trying to get Flair working or use the two prior working NLP models that are also fast
considering that in order to run flair on the pipeline we would have to load Flair's model into memory, this 
starts to become unfeasible to recreate a container in a reasonable amount of time, I'm willing to skip past this library


Methodology
- VADER and TextBlob are lexicon and rule-based.
- Flair is model-based.
Speed Performance
- Flair is slower than TextBlob and VADER because the computation algorithm is more complicated.

Without a good GPU, Flair becomes a burden for text analysis, moving forward without it for the time being


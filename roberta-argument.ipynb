{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=\"chkla/roberta-argument\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"./data/single_article.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_count\n",
       "count         1.0\n",
       "mean       1000.0\n",
       "std           NaN\n",
       "min        1000.0\n",
       "25%        1000.0\n",
       "50%        1000.0\n",
       "75%        1000.0\n",
       "max        1000.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argument_mining(article):\n",
    "    \"\"\"Runs through an article and processes each sentence in turn, then returns a dict of highlighted arguments\"\"\"\n",
    "    if article['content']:\n",
    "        text_data = article['content']\n",
    "        sentences = text_data.split(\".\")\n",
    "        \n",
    "        arguments_found = []\n",
    "        print(arguments_found)\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            print(sentence)\n",
    "            try:\n",
    "                result = classifier(sentence)\n",
    "                # the result is a list containing a dict, in the format [{'label':'ARGUMENT','score':'0.000'}]\n",
    "                # hella messy but that's why we access it like so below\n",
    "                if list(result[0].values())[0] == \"ARGUMENT\":\n",
    "                    token = []\n",
    "                    token.append(sentence)\n",
    "                    token.append(list(result[0].values())[0])\n",
    "                    token.append(list(result[0].values())[1])\n",
    "                    \n",
    "                    # store the token into the arguments_found, which will live inside the dataframe\n",
    "                    # it'll do for the time being\n",
    "                    arguments_found.append(token)\n",
    "                else:\n",
    "                    print(\"No argument has been found\")\n",
    "                    \n",
    "            except:\n",
    "                continue\n",
    "            print(arguments_found)\n",
    "        \n",
    "        return arguments_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Another strand of criticism aimed at GPT-3 and other LLMs is that the results they produce often tend to display toxicity and reproduce ethnic, racial, and other bias\n",
      "No argument has been found\n",
      "[]\n",
      " This really comes as no surprise, keeping in mind where the data used to train LLMs is coming from: the data is all generated by people, and to a large extent it has been collected from the web\n",
      "No argument has been found\n",
      "[]\n",
      " Unless corrective action is taken, its entirely expectable that LLMs will produce such output\n",
      "[[' Unless corrective action is taken, its entirely expectable that LLMs will produce such output', 'ARGUMENT', 0.5767930150032043]]\n",
      "Last but not least, LLMs take lots of resources to train and operate\n",
      "No argument has been found\n",
      "[[' Unless corrective action is taken, its entirely expectable that LLMs will produce such output', 'ARGUMENT', 0.5767930150032043]]\n",
      " Chomskys aphorism about GPT-3 is that \"its only achievement is to use up a lot of Californias energy\"\n",
      "No argument has been found\n",
      "[[' Unless corrective action is taken, its entirely expectable that LLMs will produce such output', 'ARGUMENT', 0.5767930150032043]]\n",
      " But Chomsky is not alone in pointing this out\n",
      "No argument has been found\n",
      "[[' Unless corrective action is taken, its entirely expectable that LLMs will produce such output', 'ARGUMENT', 0.5767930150032043]]\n",
      " In 2022, DeepMind published a paper, \"Training Compute-Optimal Large Language Models,\" in which analysts claim that training LLMs has been done with a deeply suboptimal use of compute\n",
      "No argument has been found\n",
      "[[' Unless corrective action is taken, its entirely expectable that LLMs will produce such output', 'ARGUMENT', 0.5767930150032043]]\n",
      "\n",
      "No argument has been found\n",
      "[[' Unless corrective action is taken, its entirely expectable that LLMs will produce such output', 'ARGUMENT', 0.5767930150032043]]\n"
     ]
    }
   ],
   "source": [
    "data_frame['arguments_found'] = data_frame.apply(lambda row: argument_mining(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>word_count</th>\n",
       "      <th>arguments_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>News and Advice on the World`s Latest Innovations</td>\n",
       "      <td>Another strand of criticism aimed at GPT-3 and...</td>\n",
       "      <td>1000</td>\n",
       "      <td>[[ Unless corrective action is taken, its enti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  News and Advice on the World`s Latest Innovations   \n",
       "\n",
       "                                             content  word_count  \\\n",
       "0  Another strand of criticism aimed at GPT-3 and...        1000   \n",
       "\n",
       "                                     arguments_found  \n",
       "0  [[ Unless corrective action is taken, its enti...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
